{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Estimating General Data Quality\n",
    "\n",
    "\n",
    "Here we plot graphs of peak I and FWHM variations for different cycles. All data were reduced using the SPHERE DC without normalisation (which is useful for this case and will be performed later)\n",
    "\n",
    "Aperture polarimetry\n",
    "\n",
    "Works for all ZIMPOL data reduced with individual cycles\n"
   ],
   "id": "6169411e15fa9077"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "4532fd2288e533c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import fnmatch\n",
    "import os\n",
    "from astropy.io import fits\n",
    "# from skimage.measure import EllipseModel\n",
    "# from matplotlib.patches import Ellipse\n",
    "# from scipy import interpolate\n",
    "# import cv2\n",
    "# from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import math\n",
    "# from textwrap import wrap\n",
    "# import scipy.ndimage as ndimage\n",
    "# from matplotlib.gridspec import GridSpec\n",
    "# from matplotlib import colors\n",
    "# import functions as f\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "# from scipy import asarray as ar,exp\n",
    "from matplotlib.ticker import ScalarFormatter,FormatStrFormatter,EngFormatter\n"
   ],
   "id": "b7c17f381590f11a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def load_and_make_polar(dirdat,camera):\n",
    "\n",
    "    dir = dirdat                                    # define data directory\n",
    "    qfile = '*sci'+camera+'.fits'                   # open camera specific file\n",
    "    files = os.listdir(dir)                         # grab all files in dir\n",
    "\n",
    "    for file in files:\n",
    "        if fnmatch.fnmatch(file, qfile):            # if file name matches\n",
    "\n",
    "            hdulq = fits.open(dir + file)           # open file and assign fluxes\n",
    "            iq = hdulq[0].data[0]\n",
    "            q = hdulq[0].data[1]\n",
    "            iu = hdulq[0].data[2]\n",
    "            u = hdulq[0].data[3]\n",
    "            n=q.shape[0]\n",
    "\n",
    "             # Creating grid\n",
    "            xr = np.linspace(-n/2, n/2, num=n)\n",
    "            yr = np.linspace(-n/2, n/2, num=n)\n",
    "            x0 = 0.5\n",
    "            y0 = 0.5\n",
    "            xr = xr-x0\n",
    "            yr = yr-y0\n",
    "            Xr, Yr = np.meshgrid(xr, yr)\n",
    "\n",
    "            R = np.sqrt(Xr**2 + Yr**2)\n",
    "            phi = np.arctan(Yr/Xr)\n",
    "            i=(iq+iu)/2\n",
    "\n",
    "            q_phi=q*np.cos(2*phi)+u*np.sin(2*phi)\n",
    "            q_phi = (q_phi > 0)*q_phi +  (q_phi <=0 )*1e-10     # q_phi polarisation flux\n",
    "            u_phi=q*np.sin(2*phi)+u*np.cos(2*phi)               # p_phi polarisation flux\n",
    "            pi=np.sqrt(q*q+u*u)\n",
    "            aolp=0.5*np.arctan2(u, q)+np.pi/2                   # angle of linear polarisation\n",
    "\n",
    "    return iq,q,iu,u,i,q_phi,u_phi,pi,aolp,R,phi\n",
    "\n",
    "def load_and_make_polar_umon(dirdat,cycle,camera):\n",
    "    #q\n",
    "    dir = dirdat+'q_corr/'\n",
    "    qfile = '*_'+cycle+'_'+camera+'.fits'\n",
    "    files = os.listdir(dir)\n",
    "    for file in files:\n",
    "        if fnmatch.fnmatch(file, qfile):\n",
    "            hdulq = fits.open(dir + file)\n",
    "            q = hdulq[0].data\n",
    "            n=q.shape[0]\n",
    "    #u\n",
    "    dir = dirdat+'u_corr/'\n",
    "    qfile = '*_'+cycle+'_'+camera+'.fits'\n",
    "    files = os.listdir(dir)\n",
    "    for file in files:\n",
    "        if fnmatch.fnmatch(file, qfile):\n",
    "            hdulq = fits.open(dir + file)\n",
    "            u = hdulq[0].data\n",
    "    #qphi\n",
    "    dir = dirdat+'qphi_corr/'\n",
    "    qfile = '*_'+cycle+'_'+camera+'.fits'\n",
    "    files = os.listdir(dir)\n",
    "    for file in files:\n",
    "        if fnmatch.fnmatch(file, qfile):\n",
    "            hdulq = fits.open(dir + file)\n",
    "            qphi = hdulq[0].data\n",
    "            \n",
    "    #uphi\n",
    "    dir = dirdat+'uphi_corr/'\n",
    "    qfile = '*_'+cycle+'_'+camera+'.fits'\n",
    "    files = os.listdir(dir)\n",
    "    for file in files:\n",
    "        if fnmatch.fnmatch(file, qfile):\n",
    "            hdulq = fits.open(dir + file)\n",
    "            uphi = hdulq[0].data\n",
    "            \n",
    "    #iq,iu\n",
    "    dir = dirdat+'sci/'\n",
    "    qfile = '*_'+cycle+'_'+camera+'.fits'\n",
    "    files = os.listdir(dir)\n",
    "    for file in files:\n",
    "        if fnmatch.fnmatch(file, qfile):\n",
    "            hdulq = fits.open(dir + file)\n",
    "            iq = hdulq[0].data[0]\n",
    "            iu = hdulq[0].data[2]\n",
    "            \n",
    "             #Creating grid         \n",
    "            xr = np.linspace(-n/2, n/2, num=n)\n",
    "            yr = np.linspace(-n/2, n/2, num=n)\n",
    "            x0 = 0.5\n",
    "            y0 = 0.5\n",
    "            xr = xr-x0\n",
    "            yr = yr-y0\n",
    "            Xr, Yr = np.meshgrid(xr, yr)\n",
    "            R = np.sqrt(Xr**2 + Yr**2)\n",
    "            phi = np.arctan(Yr/Xr)\n",
    "            \n",
    "            i=(iq+iu)/2\n",
    "            \n",
    "            qphi = (qphi > 0)*qphi +  (qphi <=0 )*1e-10\n",
    "            pi=np.sqrt(q*q+u*u)\n",
    "            aolp=0.5*np.arctan2(u, q)+np.pi/2\n",
    "            \n",
    "    return iq,q,iu,u,i,qphi,uphi,pi,aolp,R,phi\n",
    "\n",
    "def createfolder(dirName):\n",
    "    try:\n",
    "    # Create target Directory\n",
    "       os.mkdirs(dirName)\n",
    "    except FileExistsError:\n",
    "        print()#(\"Directory \" , dirName ,  \" already exists\")\n",
    "\n",
    "def create_dir(dirname):\n",
    "    if not os.path.isdir(dirname):\n",
    "        os.makedirs(dirname, exist_ok=True)\n",
    "    return dirname\n",
    "        \n",
    "def maskcrit(aolp,R):\n",
    "    # this function creates a mask to show only pixels with std of AoLP orientation from 4 neighbouring pixels is less than median\n",
    "    phi = (aolp-90)  \n",
    "    n=aolp.shape[0]\n",
    "    critarray=np.zeros_like(phi)\n",
    "\n",
    "    for ix in range (0,n):\n",
    "        for iy in range(0,n):\n",
    "            if phi[ix,iy]>180:\n",
    "                phi[ix,iy]=phi[ix,iy]-180\n",
    "\n",
    "    for ix in range (0,n-1):\n",
    "        for iy in range(0,n-1):\n",
    "            if critarray[ix,iy]==0:\n",
    "                critarray[ix,iy]=np.max(critarray)\n",
    "\n",
    "    for ix in range (2,n-2):\n",
    "        for iy in range(2,n-2):\n",
    "            if R[ix,iy]>=1:            \n",
    "                datapix=[]\n",
    "                for (iix,iiy) in [(ix,iy),(ix-1,iy),(ix+1,iy),(ix,iy-1),(ix,iy+1)]: \n",
    "                    if R[iix,iiy]>=1:\n",
    "                        datapix.append(abs(phi[iix,iiy]))\n",
    "                crit=np.std(datapix)               \n",
    "                critarray[ix,iy]=crit\n",
    "\n",
    "    medianstd=np.nanmedian(critarray)\n",
    "    mask=(critarray<=medianstd)#*R([ix,iy]>=1)\n",
    "\n",
    "    return mask\n",
    "        \n",
    "def plot_AoLP(ps,R,Q,U,I,Q_PHI,PI,AOLP,title,save):\n",
    "    # this function calculates DoLp and linear polarisation vectors on the background image.\n",
    "    # The vectors are plotted for significant region and can be re-binned to show vector field more clearly.\n",
    "    # First, we plot the background image\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    i_plot = fig.add_subplot(111)\n",
    "    n = I.shape[0]\n",
    "    d = n * ps / 2\n",
    "\n",
    "    im1=i_plot.imshow(np.arcsinh(Q_PHI), origin='lower',extent=(-d, d, d, -d))\n",
    "\n",
    "    fig.colorbar(im1, orientation='vertical')\n",
    "\n",
    "    plt.xlabel('mas')\n",
    "    plt.ylabel(\"mas\")\n",
    "    plt.tight_layout(pad=0.1)     \n",
    "\n",
    "    # ranges of the axis\n",
    "    xx0, xx1 = i_plot.get_xlim()\n",
    "    yy0, yy1 = i_plot.get_ylim()\n",
    "\n",
    "    # binning factor\n",
    "    factor = [4, 4]\n",
    "\n",
    "    # re-binned number of points in each axis\n",
    "    nx_new = PI.shape[1] // factor[0]\n",
    "    ny_new = PI.shape[0] // factor[1]\n",
    "\n",
    "    # These are the positions of the quivers (vector positions)\n",
    "    X,Y = np.meshgrid(np.linspace(xx0,xx1,nx_new,endpoint=True),\n",
    "                      np.linspace(yy0,yy1,ny_new,endpoint=True))\n",
    "    # bin the data\n",
    "    I_bin = I.reshape(nx_new, factor[0], ny_new, factor[1]).sum(3).sum(1)\n",
    "    Q_bin = Q.reshape(nx_new, factor[0], ny_new, factor[1]).sum(3).sum(1)\n",
    "    U_bin = U.reshape(nx_new, factor[0], ny_new, factor[1]).sum(3).sum(1)\n",
    "    Q_phi_bin = Q_PHI.reshape(nx_new, factor[0], ny_new, factor[1]).sum(3).sum(1)\n",
    "    PI_bin=PI.reshape(nx_new, factor[0], ny_new, factor[1]).sum(3).sum(1)\n",
    "    R_bin=R.reshape(nx_new, factor[0], ny_new, factor[1]).sum(3).sum(1)\n",
    "    aolp_bin=AOLP.reshape(nx_new, factor[0], ny_new, factor[1]).sum(3).sum(1)\n",
    "\n",
    "    # polarization angle\n",
    "    psi=0.5*np.arctan2(U_bin, Q_bin)\n",
    "\n",
    "    #psi=aolp_bin\n",
    "    #i_plot.imshow(psi, origin='lower',extent=(-d, d, d, -d))\n",
    "\n",
    "    # polarization fraction\n",
    "    frac =Q_phi_bin/I_bin\n",
    "    #frac=dolp_v[adc:bdc,adc:bdc]\n",
    "    # mask to show only aligned\n",
    "\n",
    "    mask1=maskcrit(psi,R_bin)\n",
    "    mask2=Q_phi_bin>=10\n",
    "    mask=mask2#*mask1\n",
    "    #print('max DoLP in region %.3f percent'%(np.max(frac[mask])*100))\n",
    "\n",
    "    #+pi/2 because quiver function start counting from the horizontal axis counterclockwise \n",
    "    #and the AoLP have to start from North to East (which is also counterclockvise)\n",
    "    pixX = frac*np.cos(psi+np.pi/2) # X-vector \n",
    "    pixY = frac*np.sin(psi+np.pi/2) # Y-vector\n",
    "\n",
    "    # keyword arguments for quiverplots\n",
    "    quiveropts = dict(headlength=0, headwidth=1, pivot='middle', color='w')\n",
    "    i_plot.quiver(X[mask], Y[mask], pixX[mask], pixY[mask],scale=2, **quiveropts)\n",
    "    plt.title(title)\n",
    "    plt.savefig(save,bbox_inches='tight', pad_inches=0.1)\n",
    "    #plt.show()#(dirName+\"aolp.png\",bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.close()\n",
    "    \n",
    "def gaus(x,a,x0,sigma):\n",
    "    # just a gaussian function for fitting\n",
    "    return a*np.exp(-(x-x0)**2/(2*sigma**2))\n",
    "\n",
    "def find_FWHM (PSF,n,ps,figfolder,title): \n",
    "    # this function calculates FWHM of the PSF (resolution element of the data) and also plots the PSF profile in two directions\n",
    "    middle=int(n/2)\n",
    "\n",
    "    y1=PSF[middle,middle-60:middle+60]\n",
    "    y2=PSF[middle-60:middle+60,middle]\n",
    "\n",
    "    xdata = np.linspace(middle-60,middle+60, num=len(y1))\n",
    "\n",
    "    n_gauss = len(xdata) #the number of data\n",
    "    amp=np.max(y1)\n",
    "    mean = np.sum(xdata * y1) / sum(y1)\n",
    "    sigma = np.sqrt(sum(y1 * (xdata - mean)**2) / sum(y1))\n",
    "\n",
    "    popt1,pcov1 = curve_fit(gaus,xdata,y1,p0=[amp,mean,sigma])\n",
    "    popt2,pcov2 = curve_fit(gaus,xdata,y2,p0=[amp,mean,sigma])\n",
    "\n",
    "    plt.plot(xdata, y1, 'o', label='vertical')\n",
    "    plt.plot(xdata, gaus(xdata,*popt1), '-', label='fit1')\n",
    "    plt.plot(xdata, y2, 'o', label='horizotal')\n",
    "    plt.plot(xdata, gaus(xdata,*popt2), '-', label='fit2')\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.savefig(figfolder+title+'.png',bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.close()\n",
    "\n",
    "    fwhm1=2*np.sqrt(2*math.log(2))*popt1[2]\n",
    "    fwhm2=2.355*popt2[2]\n",
    "\n",
    "    fwhm=(abs(fwhm1)+abs(fwhm2))/2*ps\n",
    "\n",
    "    return fwhm\n",
    "\n",
    "def ap_fixed_in(rad,R,q,u,PSF):\n",
    "    #this function calculates the flux in the aperture of setted outer radius            \n",
    "    mask = (R <= rad)\n",
    "    q_sum = np.sum(q[mask])\n",
    "    u_sum = np.sum(u[mask])\n",
    "    psf_sum = np.sum(PSF[mask])\n",
    "    q_i_percent = q_sum / psf_sum * 100\n",
    "    u_i_percent = u_sum / psf_sum * 100\n",
    "\n",
    "    return psf_sum, q_sum, u_sum, q_i_percent, u_i_percent\n",
    "\n",
    "def ap(radin,radout,R,q,u,PSF):\n",
    "    #this function calculates the flux in the ring with setted inner and outer radius\n",
    "    mask = (R <= radout) * (R >= radin)\n",
    "    q_sum = np.sum(q[mask])\n",
    "    u_sum = np.sum(u[mask])\n",
    "    psf_sum = np.sum(PSF[mask])\n",
    "    q_i_percent = q_sum / psf_sum * 100\n",
    "    u_i_percent = u_sum / psf_sum * 100\n",
    "\n",
    "    return psf_sum, q_sum, u_sum, q_i_percent, u_i_percent"
   ],
   "id": "a2eb55f00cab2a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#this are all target names (in my case they also correspond to directories) you have in your data folder\n",
    "#star='IRAS08544-4431'  'HD83878'   'HD75885' 'AR_Pup'\n",
    "#stars=['HR4049_20190108','HR4049_20190107','HR4226','HD71253','HD94680','HD96314','HD98025','V709_Car','HD75885', 'AR_Pup_dc_notnorm','UMon']\n",
    "\n",
    "# target names you want to run script for \n",
    "stars=['01.SCI_UMon']\n",
    "# proper target names for plot titles\n",
    "starnames = {'01.SCI_UMon':'UMon','01.SCI_AR_Pup':'AR_Pup'}\n",
    "fittypes=['1', '2'] #fittypes are the camera types in ZIMPOL (there are two cameras with different filters)\n",
    "\n",
    "band=['V','I'] #this are corresponding filters that were used for data I was working with. \n",
    "ps=3.6 #mas/pixel resolution of ZIMPOL\n",
    "\n"
   ],
   "id": "d2b9cf9388922dba"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Creating images",
   "id": "d64de7851c755460"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for star in stars:\n",
    "    #here are just correct locations of the files and directories, also after initial reduction I had every polarimetric cycle in separate directory, so there is also file with list of directories an cycle numbers\n",
    "    if star=='AR_Pup':\n",
    "        dirdat = '//media/kateryna/Data_Lin/PhD/SPHERE_reduction_data/individual_cycles/AR_Pup/Normalised/'  #For AR_Pup\n",
    "        input_filename =dirdat+'AR_Pup_indiv_process_list.csv'\n",
    "    elif star=='AR_Pup_dc_notnorm':\n",
    "        dirdat = '//media/kateryna/Data_Lin/PhD/SPHERE_reduction_data/individual_cycles/AR_Pup/Not_normalised/'  #For AR_Pup\n",
    "        input_filename =dirdat+'AR_Pup_no_norm_indiv_process_list.csv'\n",
    "\n",
    "\n",
    "    elif star=='IRAS08544-4431':\n",
    "\n",
    "        dirdat = '//media/kateryna/Data_Lin/PhD/SPHERE_reduction_data/individual_cycles/IRAS08544-4431/Normalised/'  #For IRAS08\n",
    "        input_filename =dirdat+'IRAS08process_list.csv'\n",
    "    elif star=='IRAS08544-4431_dc_notnorm':\n",
    "        dirdat = '//media/kateryna/Data_Lin/PhD/SPHERE_reduction_data/individual_cycles/IRAS08544-4431/Not_normalised/'  #For IRAS08\n",
    "        input_filename =dirdat+'IRAS08_not_norm_indiv_process_list.csv'\n",
    "    \n",
    "    elif star=='01.SCI_UMon':\n",
    "        dirdat = '/Users/aksitadeo/PycharmProjects/PythonProject/spherediskanalysis/ZIMPOL_basic_red/UMon'\n",
    "        input_filename =dirdat+'UMon_cycle_list.csv'\n",
    "        \n",
    "    else:\n",
    "        dirdat = '//media/kateryna/Data_Lin/PhD/SPHERE_reduction_data/individual_cycles/'+star+'/' \n",
    "        input_filename =dirdat+'process_list.csv'\n",
    "  \n",
    "  \n",
    "    figfolder0=('/Users/aksitadeo/PycharmProjects/PythonProject/SPHERE_data/'+star+'/quality_indv_cycles/')\n",
    "            #'//media/kateryna/Data_Lin/PhD/SPHERE_reduction_data/paper3/Quality_indiv_cycles/'+ star+'/')\n",
    "    \n",
    "    specific_folder='/Users/aksitadeo/PycharmProjects/PythonProject/SPHERE_data/'+star+'/quality_indv_cycles/'   #dirdat+'quality/'\n",
    "    \n",
    "    create_dir(specific_folder)\n",
    "    # except FileExistsError:\n",
    "    #     print(\"Directory \" , specific_folder,  \" already exists\")\n",
    "        \n",
    "    output_filename = figfolder0+star+'_V_Original_AP_per_cycle.txt'\n",
    "    df_orig_v = pd.read_csv(output_filename, delim_whitespace=True)\n",
    "    output_filename = figfolder0+star+'_I_Original_AP_per_cycle.txt'\n",
    "    df_orig_i = pd.read_csv(output_filename, delim_whitespace=True)\n",
    "  \n",
    "    output_filename = figfolder0+star+'_0-3_V_AP_per_cycle.txt'\n",
    "    df_0_3_v = pd.read_csv(output_filename, delim_whitespace=True)\n",
    "    output_filename = figfolder0+star+'_0-3_I_AP_per_cycle.txt'\n",
    "    df_0_3_i = pd.read_csv(output_filename, delim_whitespace=True)\n",
    " \n",
    "    print(df_orig_v.head())\n",
    "\n",
    "    #for paper\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    \n",
    "    # Subplot 1: Peak I\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(df_orig_v['cycle'], df_orig_v['Peak_i(Strehl)'],marker='s', label='V',color='red')\n",
    "    plt.scatter(df_orig_i['cycle'], df_orig_i['Peak_i(Strehl)'], label='I',color='blue')\n",
    "    plt.ylabel('I$_{peak}/I_{tot}$', fontsize=18)\n",
    "    formatter = ScalarFormatter(useMathText=True)\n",
    "    formatter.set_powerlimits((-2, 2))\n",
    "    plt.gca().yaxis.set_major_formatter(formatter)\n",
    "    plt.gca().yaxis.offsetText.set_fontsize(14)\n",
    "    plt.xlabel(\"cycle number\", fontsize=14)  \n",
    "    \n",
    "    plt.xticks(ticks=range(np.min(df_orig_v['cycle'])-1, np.max(df_orig_v['cycle'])+1, 5), fontsize=14)\n",
    "    plt.tick_params(axis='both', labelbottom=True,length=5,width=1.5,labelsize=14)  # Remove labeled ticks on the x-axis\n",
    "    plt.legend(fontsize=14)\n",
    "\n",
    "    # Subplot 2: Qphi\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(df_orig_v['Peak_i(Strehl)'], df_orig_v['sumQ_phi/I[%]']/100,marker='s',color='red')\n",
    "    slope, intercept = np.polyfit(df_orig_v['Peak_i(Strehl)'], df_orig_v['sumQ_phi/I[%]']/100, deg=1)\n",
    "    plt.plot(df_orig_v['Peak_i(Strehl)'],slope*df_orig_v['Peak_i(Strehl)']+intercept,color='red')\n",
    "    plt.scatter(df_orig_i['Peak_i(Strehl)'], df_orig_i['sumQ_phi/I[%]']/100,color='blue')\n",
    "    slope, intercept = np.polyfit(df_orig_i['Peak_i(Strehl)'], df_orig_i['sumQ_phi/I[%]']/100, deg=1)\n",
    "    plt.plot(df_orig_i['Peak_i(Strehl)'],slope*df_orig_i['Peak_i(Strehl)']+intercept,color='blue')\n",
    "    plt.ylabel('$Q_{\\phi}/I_{tot}$', fontsize=18)\n",
    "    plt.xlabel(\"$I_{peak}/I_{tot}$\", fontsize=14)  \n",
    "    formatter = ScalarFormatter(useMathText=True)\n",
    "    formatter.set_powerlimits((-1, 2))\n",
    "    plt.gca().yaxis.set_major_formatter(formatter)\n",
    "    plt.gca().yaxis.offsetText.set_fontsize(14)\n",
    "    plt.gca().xaxis.set_major_formatter(formatter)\n",
    "    plt.gca().xaxis.offsetText.set_fontsize(14)\n",
    "    #plt.xticks(ticks=range(np.min(df_orig_v['cycle'])-1, np.max(df_orig_v['cycle'])+1, 5), fontsize=14)\n",
    "    plt.tick_params(axis='both',length=5,width=1.5,labelsize=14) \n",
    "   \n",
    "    # Adjust x-axis limits to include the last tick\n",
    "    #plt.xlim(np.min(df_orig_v['cycle'])-1, np.max(df_orig_v['cycle'])+1)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(specific_folder + star + '_for_thesis.png', bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.show()\n",
    "    plt.close()"
   ],
   "id": "6cc42f273b9a8b3a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bc3878d70fabee50"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
