{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Filtering polarimetric cycles for SPHERE-DC reduced data without normalisation based on the peak I and copying into separate folder.\n",
    "## Mean combining for the I\n"
   ],
   "id": "61414ab0d0237af3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T02:30:42.529007Z",
     "start_time": "2025-09-02T02:30:42.434061Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import fnmatch\n",
    "import os\n",
    "from astropy.io import fits\n",
    "from skimage.measure import EllipseModel\n",
    "from matplotlib.patches import Ellipse\n",
    "from scipy import interpolate\n",
    "import cv2\n",
    "import math\n",
    "from textwrap import wrap\n",
    "import scipy.ndimage as ndimage\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib import colors\n",
    "import functions as f\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "#calculating mean-combined versions and multiply\n",
    "\n",
    "def load_and_make_polar(dirdat,camera):\n",
    "    dir = dirdat\n",
    "    qfile = '*sci'+camera+'.fits'\n",
    "    files = os.listdir(dir)\n",
    "    for file in files:\n",
    "        if fnmatch.fnmatch(file, qfile):\n",
    "            hdulq = fits.open(dir + file)\n",
    "            iq = hdulq[0].data[0]\n",
    "            q = hdulq[0].data[1]\n",
    "            iu = hdulq[0].data[2]\n",
    "            u = hdulq[0].data[3]\n",
    "            n=q.shape[0]\n",
    "             #Creating grid         \n",
    "            xr = np.linspace(-n/2, n/2, num=n)\n",
    "            yr = np.linspace(-n/2, n/2, num=n)\n",
    "            x0 = 0.5\n",
    "            y0 = 0.5\n",
    "            xr = xr-x0\n",
    "            yr = yr-y0\n",
    "            Xr, Yr = np.meshgrid(xr, yr)\n",
    "            R = np.sqrt(Xr**2 + Yr**2)\n",
    "            phi = np.arctan(Yr/Xr)\n",
    "            i=(iq+iu)/2\n",
    "            q_phi=q*np.cos(2*phi)+u*np.sin(2*phi)\n",
    "            # q_phi = (q_phi > 0)*q_phi +  (q_phi <=0 )*1e-10\n",
    "            u_phi=q*np.sin(2*phi)+u*np.cos(2*phi)\n",
    "            pi=np.sqrt(q*q+u*u)\n",
    "            aolp=0.5*np.arctan2(u, q)+np.pi/2\n",
    "    return iq,q,iu,u,i,q_phi,u_phi,pi,aolp,R,phi\n",
    "\n",
    "def load_and_make_polar_umon(dirdat,cycle,camera):\n",
    "    #q\n",
    "    dir = dirdat+'q_corr/'\n",
    "    qfile = '*_'+cycle+'_'+camera+'.fits'\n",
    "    files = os.listdir(dir)\n",
    "    for file in files:\n",
    "        if fnmatch.fnmatch(file, qfile):\n",
    "            hdulq = fits.open(dir + file)\n",
    "            q = hdulq[0].data\n",
    "            n=q.shape[0]\n",
    "    #u\n",
    "    dir = dirdat+'u_corr/'\n",
    "    qfile = '*_'+cycle+'_'+camera+'.fits'\n",
    "    files = os.listdir(dir)\n",
    "    for file in files:\n",
    "        if fnmatch.fnmatch(file, qfile):\n",
    "            hdulq = fits.open(dir + file)\n",
    "            u = hdulq[0].data\n",
    "    #qphi\n",
    "    dir = dirdat+'qphi_corr/'\n",
    "    qfile = '*_'+cycle+'_'+camera+'.fits'\n",
    "    files = os.listdir(dir)\n",
    "    for file in files:\n",
    "        if fnmatch.fnmatch(file, qfile):\n",
    "            hdulq = fits.open(dir + file)\n",
    "            qphi = hdulq[0].data\n",
    "            \n",
    "    #uphi\n",
    "    dir = dirdat+'uphi_corr/'\n",
    "    qfile = '*_'+cycle+'_'+camera+'.fits'\n",
    "    files = os.listdir(dir)\n",
    "    for file in files:\n",
    "        if fnmatch.fnmatch(file, qfile):\n",
    "            hdulq = fits.open(dir + file)\n",
    "            uphi = hdulq[0].data\n",
    "            \n",
    "            \n",
    "            \n",
    "    #iq,iu\n",
    "    dir = dirdat+'sci/'\n",
    "    qfile = '*_'+cycle+'_'+camera+'.fits'\n",
    "    files = os.listdir(dir)\n",
    "    for file in files:\n",
    "        if fnmatch.fnmatch(file, qfile):\n",
    "            hdulq = fits.open(dir + file)\n",
    "            iq = hdulq[0].data[0]\n",
    "            iu = hdulq[0].data[2]\n",
    "            \n",
    "            \n",
    "            \n",
    "             #Creating grid         \n",
    "            xr = np.linspace(-n/2, n/2, num=n)\n",
    "            yr = np.linspace(-n/2, n/2, num=n)\n",
    "            x0 = 0.5\n",
    "            y0 = 0.5\n",
    "            xr = xr-x0\n",
    "            yr = yr-y0\n",
    "            Xr, Yr = np.meshgrid(xr, yr)\n",
    "            R = np.sqrt(Xr**2 + Yr**2)\n",
    "            phi = np.arctan(Yr/Xr)\n",
    "            \n",
    "            i=(iq+iu)/2\n",
    "            \n",
    "            # qphi = (qphi > 0)*qphi +  (qphi <=0 )*1e-10\n",
    "            pi=np.sqrt(q*q+u*u)\n",
    "            aolp=0.5*np.arctan2(u, q)+np.pi/2\n",
    "            \n",
    "    return iq,q,iu,u,i,qphi,uphi,pi,aolp,R,phi\n",
    "\n",
    "def Loadimage(dirdat,filename):\n",
    "    dir =dirdat\n",
    "    psfile =  filename\n",
    "    files = os.listdir(dir)\n",
    "    for file in files:\n",
    "        if fnmatch.fnmatch(file, psfile):\n",
    "            hdulPSF = fits.open(dir + file)\n",
    "            fit = hdulPSF[0].data\n",
    "\n",
    "            \n",
    "    return fit"
   ],
   "id": "cd2922ac2680f7b1",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T02:30:44.731549Z",
     "start_time": "2025-09-02T02:30:44.707008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_tel_corr(dirdat,camera,process):\n",
    "    dir = dirdat\n",
    "    files = os.listdir(dir)\n",
    "    qfile = 'qcorr_'+str(process)+'_'+str(camera)+'.fits'\n",
    "    ufile = 'ucorr_'+str(process)+'_'+str(camera)+'.fits'\n",
    "    qphifile = 'qphi_'+str(process)+'_'+str(camera)+'.fits'\n",
    "    uphifile = 'uphi_'+str(process)+'_'+str(camera)+'.fits'\n",
    "    \n",
    "    for file in files:\n",
    "        if fnmatch.fnmatch(file, qfile):\n",
    "            hdulq = fits.open(dir + file)\n",
    "            q = hdulq[0].data\n",
    "        if fnmatch.fnmatch(file, ufile):\n",
    "            hdulq = fits.open(dir + file)\n",
    "            u = hdulq[0].data\n",
    "        #if fnmatch.fnmatch(file, qphifile):\n",
    "        #    hdulq = fits.open(dir + file)\n",
    "        #    q_phi = hdulq[0].data\n",
    "        #if fnmatch.fnmatch(file, uphifile):\n",
    "        #    hdulq = fits.open(dir + file)\n",
    "        #    u_phi = hdulq[0].data    \n",
    "            \n",
    "            \n",
    "    n=q.shape[0]\n",
    "     #Creating grid         \n",
    "    xr = np.linspace(-n/2, n/2, num=n)\n",
    "    yr = np.linspace(-n/2, n/2, num=n)\n",
    "    x0 = 0.5\n",
    "    y0 = 0.5\n",
    "    xr = xr-x0\n",
    "    yr = yr-y0\n",
    "    Xr, Yr = np.meshgrid(xr, yr)\n",
    "    R = np.sqrt(Xr**2 + Yr**2)\n",
    "    phi = np.arctan(Yr/Xr)\n",
    "    q_phi=q*np.cos(2*phi)+u*np.sin(2*phi)\n",
    "    # q_phi = (q_phi > 0)*q_phi +  (q_phi <=0 )*1e-10\n",
    "    u_phi=q*np.sin(2*phi)+u*np.cos(2*phi)    \n",
    "    \n",
    "    return q,u,q_phi,u_phi\n",
    "\n",
    "def createfolder(dirName):\n",
    "    try:\n",
    "    # Create target Directory\n",
    "       os.mkdir(dirName)\n",
    "    except FileExistsError:\n",
    "        print()#(\"Directory \" , dirName ,  \" already exists\")   \n",
    "\n",
    "def maskcrit(aolp,R):\n",
    "    phi = (aolp-90)  \n",
    "    n=aolp.shape[0]\n",
    "    critarray=np.zeros_like(phi)\n",
    "    for ix in range (0,n):\n",
    "        for iy in range(0,n):\n",
    "            if phi[ix,iy]>180:\n",
    "                phi[ix,iy]=phi[ix,iy]-180\n",
    "            \n",
    "    for ix in range (2,n-2):\n",
    "        for iy in range(2,n-2):\n",
    "            if R[ix,iy]>=1:            \n",
    "                datapix=[]\n",
    "                for (iix,iiy) in [(ix,iy),(ix-1,iy),(ix+1,iy),(ix,iy-1),(ix,iy+1)]: \n",
    "                    if R[iix,iiy]>=1:\n",
    "                        datapix.append(abs(phi[iix,iiy]))\n",
    "                            \n",
    "                \n",
    "                crit=np.std(datapix)               \n",
    "                critarray[ix,iy]=crit\n",
    "                \n",
    "    for ix in range (0,n-1):\n",
    "        for iy in range(0,n-1):\n",
    "            if critarray[ix,iy]==0:\n",
    "                critarray[ix,iy]=np.max(critarray)\n",
    "    medianstd=np.nanmedian(critarray)\n",
    "    \n",
    "    mask=(critarray<=medianstd)#*R([ix,iy]>=1)\n",
    "    return mask\n",
    "        \n",
    "def plot_AoLP(ps,R,Q,U,I,Q_PHI,PI,AOLP,title,save):\n",
    "    # First, we plot the background image\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    i_plot = fig.add_subplot(111)\n",
    "    n = I.shape[0]\n",
    "    d = n * ps / 2\n",
    "\n",
    "    im1=i_plot.imshow(np.arcsinh(Q_PHI), origin='lower',extent=(-d, d, d, -d))\n",
    "\n",
    "    fig.colorbar(im1, orientation='vertical')\n",
    "\n",
    "    plt.xlabel('mas')\n",
    "    plt.ylabel(\"mas\")\n",
    "    plt.tight_layout(pad=0.1)     \n",
    "\n",
    "    # ranges of the axis\n",
    "    xx0, xx1 = i_plot.get_xlim()\n",
    "    yy0, yy1 = i_plot.get_ylim()\n",
    "\n",
    "    # binning factor\n",
    "    factor = [4, 4]\n",
    "\n",
    "    # re-binned number of points in each axis\n",
    "    nx_new = PI.shape[1] // factor[0]\n",
    "    ny_new = PI.shape[0] // factor[1]\n",
    "\n",
    "    # These are the positions of the quivers\n",
    "    X,Y = np.meshgrid(np.linspace(xx0,xx1,nx_new,endpoint=True),\n",
    "                      np.linspace(yy0,yy1,ny_new,endpoint=True))\n",
    "    # bin the data\n",
    "    I_bin = I.reshape(nx_new, factor[0], ny_new, factor[1]).sum(3).sum(1)\n",
    "    Q_bin = Q.reshape(nx_new, factor[0], ny_new, factor[1]).sum(3).sum(1)\n",
    "    U_bin = U.reshape(nx_new, factor[0], ny_new, factor[1]).sum(3).sum(1)\n",
    "    Q_phi_bin = Q_PHI.reshape(nx_new, factor[0], ny_new, factor[1]).sum(3).sum(1)\n",
    "    PI_bin=PI.reshape(nx_new, factor[0], ny_new, factor[1]).sum(3).sum(1)\n",
    "    R_bin=R.reshape(nx_new, factor[0], ny_new, factor[1]).sum(3).sum(1)\n",
    "    aolp_bin=AOLP.reshape(nx_new, factor[0], ny_new, factor[1]).sum(3).sum(1)\n",
    "\n",
    "    # polarization angle\n",
    "    psi=0.5*np.arctan2(U_bin, Q_bin)\n",
    "\n",
    "    #psi=aolp_bin\n",
    "    #i_plot.imshow(psi, origin='lower',extent=(-d, d, d, -d))\n",
    "\n",
    "    # polarization fraction\n",
    "    frac =Q_phi_bin/I_bin\n",
    "    #frac=dolp_v[adc:bdc,adc:bdc]\n",
    "    # mask to show only alighned\n",
    "\n",
    "    mask1=maskcrit(psi,R_bin)\n",
    "    mask2=Q_phi_bin>=10\n",
    "    mask=mask2#*mask1\n",
    "    #print('max DoLP in region %.3f percent'%(np.max(frac[mask])*100))\n",
    "\n",
    "    #+pi/2 because quiver function start counting from the horizontal axis counterclockwise \n",
    "    #and the AoLP have to start from North to East (which is also counterclockvise)\n",
    "    pixX = frac*np.cos(psi+np.pi/2) # X-vector \n",
    "    pixY = frac*np.sin(psi+np.pi/2) # Y-vector\n",
    "\n",
    "    # keyword arguments for quiverplots\n",
    "    quiveropts = dict(headlength=0, headwidth=1, pivot='middle', color='w')\n",
    "    i_plot.quiver(X[mask], Y[mask], pixX[mask], pixY[mask],scale=2, **quiveropts)\n",
    "    plt.title(title)\n",
    "    plt.savefig(save,bbox_inches='tight', pad_inches=0.1)\n",
    "    #plt.show()#(dirName+\"aolp.jpeg\",bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.close()\n",
    "    \n",
    "def gaus(x,a,x0,sigma):\n",
    "            return a*np.exp(-(x-x0)**2/(2*sigma**2))\n",
    "    \n",
    "def find_FWHM (PSF,n,ps,figfolder,title):             #resolution\n",
    "    middle=int(n/2)\n",
    "\n",
    "    y1=PSF[middle,middle-60:middle+60]\n",
    "    y2=PSF[middle-60:middle+60,middle]\n",
    "\n",
    "    xdata = np.linspace(middle-60,middle+60, num=len(y1))\n",
    "\n",
    "\n",
    "    n_gauss = len(xdata) #the number of data\n",
    "    amp=np.max(y1)\n",
    "    mean = np.sum(xdata * y1) / sum(y1)\n",
    "    sigma = np.sqrt(sum(y1 * (xdata - mean)**2) / sum(y1))\n",
    "\n",
    "    popt1,pcov1 = curve_fit(gaus,xdata,y1,p0=[amp,mean,sigma])\n",
    "    popt2,pcov2 = curve_fit(gaus,xdata,y2,p0=[amp,mean,sigma])\n",
    "\n",
    "\n",
    "    plt.plot(xdata, y1, 'o', label='vertical')\n",
    "    plt.plot(xdata, gaus(xdata,*popt1), '-', label='fit1')\n",
    "    plt.plot(xdata, y2, 'o', label='horizotal')\n",
    "    plt.plot(xdata, gaus(xdata,*popt2), '-', label='fit2')\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.savefig(figfolder+title+'.jpeg',bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.close()\n",
    "\n",
    "    fwhm1=2*np.sqrt(2*math.log(2))*popt1[2]\n",
    "    fwhm2=2.355*popt2[2]\n",
    "\n",
    "\n",
    "    fwhm=(abs(fwhm1)+abs(fwhm2))/2\n",
    "\n",
    "    return fwhm\n",
    "\n",
    "def ap_fixed_in(rad,R,q,u,PSF):            \n",
    "    mask = (R <= rad)\n",
    "    q_sum = np.sum(q[mask])\n",
    "    u_sum = np.sum(u[mask])\n",
    "    psf_sum = np.sum(PSF[mask])\n",
    "    q_i_percent = q_sum / psf_sum * 100\n",
    "    u_i_percent = u_sum / psf_sum * 100\n",
    "    return psf_sum, q_sum, u_sum, q_i_percent, u_i_percent\n",
    "\n",
    "def ap(radin,radout,R,q,u,PSF):\n",
    "    mask = (R <= radout) * (R >= radin)\n",
    "    q_sum = np.sum(q[mask])\n",
    "    u_sum = np.sum(u[mask])\n",
    "    psf_sum = np.sum(PSF[mask])\n",
    "    q_i_percent = q_sum / psf_sum * 100\n",
    "    u_i_percent = u_sum / psf_sum * 100\n",
    "\n",
    "    return psf_sum, q_sum, u_sum, q_i_percent, u_i_percent\n",
    "\n",
    "def Loadimagespsf_AR(star):\n",
    "    dir = '/media/kateryna/Data_Lin/PhD/SPHERE_reduction_data/classic_reduction/'+star+'/'\n",
    " \n",
    "    psfile =  '*REDUCED_I.fits'\n",
    "    files = os.listdir(dir)\n",
    "    for file in files:\n",
    "        if fnmatch.fnmatch(file, psfile):\n",
    "            hdulPSF = fits.open(dir + file)\n",
    "            PSFv = hdulPSF[0].data[0]\n",
    "            PSFi = hdulPSF[0].data[1]\n",
    "\n",
    "            \n",
    "    return PSFv,PSFi\n",
    "\n",
    "def unres_correction(iq,iu,q,u):\n",
    "\n",
    "    n=q.shape[0]\n",
    "     #Creating grid         \n",
    "    xr = np.linspace(-n/2, n/2, num=n)\n",
    "    yr = np.linspace(-n/2, n/2, num=n)\n",
    "    x0 = 0.5\n",
    "    y0 = 0.5\n",
    "    xr = xr-x0\n",
    "    yr = yr-y0\n",
    "    Xr, Yr = np.meshgrid(xr, yr)\n",
    "    R = np.sqrt(Xr**2 + Yr**2)\n",
    "    phi = np.arctan(Yr/Xr)\n",
    "    i=(iq+iu)/2\n",
    "    mask=(R<=3)\n",
    "\n",
    "    q_over_i=np.divide(q,i,where=i!=0)   \n",
    "    cq=np.median(q_over_i[mask]) #for median normal as in IRDIS\n",
    "    u_over_i=np.divide(u,i,where=i!=0)    \n",
    "    cu=np.median(u_over_i[mask]) #for median normal as in IRDIS\n",
    "    q_corr=q-cq*iq\n",
    "    u_corr=u-cu*iu\n",
    "\n",
    "    q_phi=q_corr*np.cos(2*phi)+u_corr*np.sin(2*phi)\n",
    "    # q_phi= (q_phi> 0)*q_phi +  (q_phi <=0 )*1e-10\n",
    "    u_phi=q_corr*np.sin(2*phi)+u_corr*np.cos(2*phi)\n",
    "    pi=np.sqrt(q_corr*q_corr+u_corr*u_corr)\n",
    "    aolp=0.5*np.arctan2(u, q)+np.pi/2\n",
    "\n",
    "    return iq,q_corr,iu,u_corr,i,q_phi,u_phi,pi,aolp,R,phi\n",
    "\n",
    "def load_I(dirdat,camera):\n",
    "    dir = dirdat\n",
    "    qfile = '*sci'+camera+'.fits'\n",
    "    files = os.listdir(dir)\n",
    "    for file in files:\n",
    "        if fnmatch.fnmatch(file, qfile):\n",
    "            hdulq = fits.open(dir + file)\n",
    "            iq = hdulq[0].data[0]\n",
    "            q = hdulq[0].data[1]\n",
    "            iu = hdulq[0].data[2]\n",
    "            u = hdulq[0].data[3]\n",
    "            n=q.shape[0]\n",
    "            i=(iq+iu)/2\n",
    "            \n",
    "    return iq,iu,i\n"
   ],
   "id": "49664f31cb5722b7",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Downloading files and selecting top percent by peak I",
   "id": "fee769f3d61dd052"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T02:32:28.401062Z",
     "start_time": "2025-09-02T02:32:28.366554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stars=['REF_HD71253','01.SCI_UMon','REF_HD75885','01.SCI_AR_Pup']\n",
    "star=stars[0]\n",
    "\n",
    "starnames = {'01.SCI_UMon':'UMon','01.SCI_AR_Pup':'AR_Pup','REF_HD71253':'HD71253','REF_HD75885':'HD75885'}\n",
    "fittypes=['1', '2']\n",
    "\n",
    "band=['V','I']\n",
    "ps=3.6\n",
    "\n",
    "if star=='AR_Pup':\n",
    "    dirdat = '/Users/aksitadeo/PycharmProjects/PythonProject/spherediskanalysis/codes/AR_Pup/'  #For AR_Pup\n",
    "    input_filename =dirdat+'AR_Pup_indiv_process_list.csv'\n",
    "elif star=='01.SCI_AR_Pup':\n",
    "    dirdat = '/Users/aksitadeo/PycharmProjects/PythonProject/spherediskanalysis/ZIMPOL_basic_red/AR_Pup/'  #For AR_Pup\n",
    "    input_filename =dirdat+'AR_Pup_no_norm_indiv_process_list.csv'\n",
    "\n",
    "elif star=='01.SCI_UMon':\n",
    "    dirdat = '/Users/aksitadeo/PycharmProjects/PythonProject/spherediskanalysis/ZIMPOL_basic_red/UMon/'\n",
    "    input_filename =dirdat+'process_list.csv'\n",
    "\n",
    "else:\n",
    "    dirdat = '/Users/aksitadeo/PycharmProjects/PythonProject/spherediskanalysis/ZIMPOL_basic_red/'+starnames[star]+'/'\n",
    "    input_filename =dirdat+'process_list.csv'\n",
    "    \n",
    "table = pd.read_csv(input_filename)\n",
    "table['reference']= table['reference'].str.replace(' ', '_') #ix in case there are spaces in the name\n",
    "\n",
    "figfolder='/Users/aksitadeo/PycharmProjects/PythonProject/SPHERE_data/'+star+'/Quality_indiv_cycles/'\n",
    "\n",
    "output_filename = figfolder+'no_unres_correction/'+star+'_V_Original_AP_per_cycle.txt'\n",
    "df_orig_v = pd.read_csv(output_filename, delim_whitespace=True)\n",
    "output_filename = figfolder+'no_unres_correction/'+star+'_I_Original_AP_per_cycle.txt'\n",
    "df_orig_i = pd.read_csv(output_filename, delim_whitespace=True)\n",
    "\n",
    "#stars = ['HD75885','AR_Pup','HR4049/2019-01-08','HR4049/2019-01-07','IRAS08544-4431','UMon','V709_Car','UMon_calibV390','HR4224']\n",
    "\n",
    "processes=table['id']\n",
    "\n",
    "reference={process:ref for process,ref in zip(table['id'], table['reference'])}\n",
    "process_dict={ref:process for process,ref in zip(table['id'], table['reference'])}\n",
    "\n",
    "percentile_25 = np.percentile(df_orig_v['Peak_i(Strehl)'], 25)\n",
    "print(percentile_25)\n",
    "print(np.max(df_orig_v['Peak_i(Strehl)']))\n",
    "\n",
    "#filtering list of processes\n",
    "filtered_process_dict = {key: value for key, value in process_dict.items() if df_orig_v[df_orig_v['reference'] == key]['Peak_i(Strehl)'].values[0] >=percentile_25}\n",
    "\n",
    "print(filtered_process_dict)\n",
    "print(len(filtered_process_dict))\n",
    "\n",
    "#for key, value in process_dict.items():\n",
    " #   print(key, df_orig_v[df_orig_v['reference'] == key]['FWHM'].values[0])"
   ],
   "id": "7fb0c2f117316913",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0025325\n",
      "0.003314\n",
      "{'HD71253_11c_06_12-13_not_norm': 573463, 'HD71253_9c_06_10-11_not_norm': 573462, 'HD71253_8c_06_08-10(1)_not_norm': 573461, 'HD71253_7c_06_06-08(1)_not_norm': 573460, 'HD71253_6c_06_04-06(1)_not_norm': 573459, 'HD71253_5c_06_02-04(1)_not_norm': 573458, 'HD71253_4c_06_01-02(1)_not_norm': 573457}\n",
      "7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xc/tr18j41x0lgdjpw201cfd6w00000gp/T/ipykernel_74763/3995675292.py:31: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df_orig_v = pd.read_csv(output_filename, delim_whitespace=True)\n",
      "/var/folders/xc/tr18j41x0lgdjpw201cfd6w00000gp/T/ipykernel_74763/3995675292.py:33: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df_orig_i = pd.read_csv(output_filename, delim_whitespace=True)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T02:32:34.857675Z",
     "start_time": "2025-09-02T02:32:34.853302Z"
    }
   },
   "cell_type": "code",
   "source": "star",
   "id": "465a1dbf0bf8927d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'REF_HD71253'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T02:32:38.246095Z",
     "start_time": "2025-09-02T02:32:38.038171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import shutil\n",
    "import csv\n",
    "\n",
    "def create_dir(dirname):\n",
    "    if not os.path.isdir(dirname):\n",
    "        os.makedirs(dirname, exist_ok=True)\n",
    "    return dirname\n",
    "\n",
    "# target_star = 'HD71253'\n",
    "fitsfolder = '/Users/aksitadeo/PycharmProjects/PythonProject/SPHERE_data/'+star+'/filtered/selected/'\n",
    "create_dir(fitsfolder)\n",
    "\n",
    "with open(fitsfolder+'filtered_process_list.csv', 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(['reference', 'process'])\n",
    "    \n",
    "    for reference,process in filtered_process_dict.items():\n",
    "        csv_writer.writerow([reference,process])\n",
    "\n",
    "for fittype in fittypes:\n",
    "    \n",
    "    fitsfolder0=fitsfolder+'cam'+fittype+'/'\n",
    "    createfolder(fitsfolder0)\n",
    "    print(band[int(fittype)-1])\n",
    "    for key in filtered_process_dict.keys():\n",
    "        process=filtered_process_dict[key]\n",
    "        if star!='UMon':\n",
    "            dirName=dirdat+'SPHERE_DC_DATA/'+str(process)+'/'\n",
    "            qfile = '*sci'+fittype+'.fits'\n",
    "            files = os.listdir(dirName)\n",
    "            for file in files:\n",
    "                if fnmatch.fnmatch(file, qfile):\n",
    "                    shutil.copyfile(dirName+file,fitsfolder0+str(process)+'_'+file)\n",
    "                \n",
    "        if star=='UMon':\n",
    "            for folder in ['q_corr','u_corr','qphi_corr','uphi_corr','sci']:\n",
    "                fitsfolder_sub=fitsfolder0+folder+'/'\n",
    "                createfolder(fitsfolder_sub)    \n",
    "                dirName=dirdat+folder+'/'\n",
    "                qfile = '*'+process+'_'+fittype+'.fits'\n",
    "\n",
    "                files = os.listdir(dirName)\n",
    "                for file in files:\n",
    "                    if fnmatch.fnmatch(file, qfile):\n",
    "                        shutil.copyfile(dirName+file,fitsfolder_sub+str(process)+'_'+file)\n"
   ],
   "id": "35beabd88b38aba9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V\n",
      "I\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Mean combining I total and saving as fits",
   "id": "e6a08b1c01693abf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T02:32:41.474559Z",
     "start_time": "2025-09-02T02:32:40.949159Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# #Images of the mean_combined data\n",
    "# figfolder='//media/kateryna/Data_Lin/PhD/SPHERE_reduction_data/paper3/'+'filtered/'\n",
    "# createfolder(figfolder)\n",
    "# figfolder=figfolder+star+'/'\n",
    "# createfolder(figfolder)\n",
    "print(\"{:<30} {:<10}  \\n\".format('reference', 'Peak_I(Strehl)'))\n",
    "\n",
    "for fittype in fittypes:\n",
    "    print(band[int(fittype)-1])\n",
    "    iq_arr=[]\n",
    "    iu_arr=[]\n",
    "    q_arr=[]\n",
    "    u_arr=[]\n",
    "    i_arr=[]\n",
    "    q_phi_arr=[]\n",
    "    u_phi_arr=[]\n",
    "    pi_arr=[]\n",
    "    \n",
    "    for key in filtered_process_dict.keys():\n",
    "        process=filtered_process_dict[key]\n",
    "        if star=='UMon':\n",
    "            dirName=dirdat\n",
    "        else:\n",
    "            dirName=dirdat+'SPHERE_DC_DATA/'+str(process)+'/'\n",
    "        if star=='UMon':\n",
    "            iq,_,iu,_,i,_,_,_,_,_,_= load_and_make_polar_umon(dirName,process,fittype)\n",
    "        else:        \n",
    "            iq,iu,i= load_I(dirName,fittype)\n",
    "        iq_arr.append(iq)\n",
    "        iu_arr.append(iu)\n",
    "        i_arr.append(i)\n",
    "        \n",
    "    iq_arr=np.array(iq_arr)\n",
    "    iu_arr=np.array(iu_arr)\n",
    "    i_arr=np.array(i_arr)\n",
    "\n",
    "    iq_mean_comb=np.mean(iq_arr,axis=0)\n",
    "    iu_mean_comb=np.mean(iu_arr,axis=0)\n",
    "    i_mean_comb=np.mean(i_arr,axis=0)\n",
    "\n",
    "    n=iq_mean_comb.shape[0]\n",
    "    if star=='01.SCI_AR_Pup' or star=='REF_HD75885':\n",
    "        lim=100       \n",
    "    else:\n",
    "        lim=50       \n",
    "            \n",
    "    xr = np.linspace(-n/2, n/2, num=n)\n",
    "    yr = np.linspace(-n/2, n/2, num=n)\n",
    "    x0 = 0.5\n",
    "    y0 = 0.5\n",
    "    xr = xr-x0\n",
    "    yr = yr-y0\n",
    "    Xr, Yr = np.meshgrid(xr, yr)\n",
    "    R = np.sqrt(Xr**2 + Yr**2)\n",
    "    \n",
    "    mask=(R<=1500/ps)\n",
    "    I_sum=np.sum(i_mean_comb[mask])\n",
    "    \n",
    "    fwhm=find_FWHM (i_mean_comb,n,ps,figfolder,band[int(fittype)-1]+'_gauss_mean_combined')\n",
    "    \n",
    "    mask=(R<=1500/ps)\n",
    "    #calculating what is the ratio of peak brightness to the total. For I it refers to the observational conditions and is a proxy of strehl\n",
    "    normalisation=np.sum(i_mean_comb[mask])\n",
    "    peak_i=np.max(i_mean_comb*(R<200))/normalisation\n",
    "    \n",
    "    line = \"{:<30} {:<10.3f} \\n\".format('raw',peak_i)\n",
    "    print(line)\n",
    "\n",
    "    filename={0:'I'}\n",
    "\n",
    "    for fileindex,image1 in enumerate([i_mean_comb]):\n",
    "        out_fits = fits.HDUList(fits.PrimaryHDU(image1))                  # create output fits structure\n",
    "        out_fits.writeto(figfolder+star+'_'+band[int(fittype)-1]+'_'+filename[fileindex]+'_meancombined.fits', overwrite = True)                       # write output\n",
    "\n",
    "        image_an = image1*(R<250)\n",
    "        image=np.arcsinh(image_an)\n",
    "        fig, ax = plt.subplots()\n",
    "        f.plottingroutinemas(image,lim,ps,n,star,ax)        \n",
    "        f.scale_mas(star,ax)  \n",
    "\n",
    "        plt.title(starnames[star]+', '+filename[fileindex]+', '+band[int(fittype)-1]+', mean combined')\n",
    "        plt.savefig(figfolder+star+'_'+band[int(fittype)-1]+'_'+filename[fileindex]+'_'+'_meancombined.jpeg',bbox_inches='tight', pad_inches=0.1)\n",
    "        #plt.show()\n",
    "        plt.close()\n"
   ],
   "id": "a267707036573909",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reference                      Peak_I(Strehl)  \n",
      "\n",
      "V\n",
      "raw                            0.003      \n",
      "\n",
      "I\n",
      "raw                            0.004      \n",
      "\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T02:32:42.118465Z",
     "start_time": "2025-09-02T02:32:42.114710Z"
    }
   },
   "cell_type": "code",
   "source": "figfolder",
   "id": "c060130a41644eba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/aksitadeo/PycharmProjects/PythonProject/SPHERE_data/REF_HD71253/Quality_indiv_cycles/'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a0706e5f7b602bf0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
