{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d60ef921-6b16-42f8-a23c-40727731363a",
   "metadata": {},
   "source": [
    "# Filtering polarimertric cycles for SPHERE-DC reduced data without normalisation based on the peakI and copying into separate folder.\n",
    "## Mean combining for the I\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22bce68b-2b18-4a00-a5fb-d3279e50bd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import fnmatch\n",
    "import os\n",
    "from astropy.io import fits\n",
    "from skimage.measure import EllipseModel\n",
    "from matplotlib.patches import Ellipse\n",
    "from scipy import interpolate\n",
    "import cv2\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import math\n",
    "from textwrap import wrap\n",
    "import scipy.ndimage as ndimage\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib import colors\n",
    "import functions as f\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import asarray as ar,exp\n",
    "\n",
    "#calculating mean-combined versions and multiply\n",
    "\n",
    "def load_and_make_polar(dirdat,camera):\n",
    "    dir = dirdat\n",
    "    qfile = '*sci'+camera+'.fits'\n",
    "    files = os.listdir(dir)\n",
    "    for file in files:\n",
    "        if fnmatch.fnmatch(file, qfile):\n",
    "            hdulq = fits.open(dir + file)\n",
    "            iq = hdulq[0].data[0]\n",
    "            q = hdulq[0].data[1]\n",
    "            iu = hdulq[0].data[2]\n",
    "            u = hdulq[0].data[3]\n",
    "            n=q.shape[0]\n",
    "             #Creating grid         \n",
    "            xr = np.linspace(-n/2, n/2, num=n)\n",
    "            yr = np.linspace(-n/2, n/2, num=n)\n",
    "            x0 = 0.5\n",
    "            y0 = 0.5\n",
    "            xr = xr-x0\n",
    "            yr = yr-y0\n",
    "            Xr, Yr = np.meshgrid(xr, yr)\n",
    "            R = np.sqrt(Xr**2 + Yr**2)\n",
    "            phi = np.arctan(Yr/Xr)\n",
    "            i=(iq+iu)/2\n",
    "            q_phi=q*np.cos(2*phi)+u*np.sin(2*phi)\n",
    "            q_phi = (q_phi > 0)*q_phi +  (q_phi <=0 )*1e-10\n",
    "            u_phi=q*np.sin(2*phi)+u*np.cos(2*phi)\n",
    "            pi=np.sqrt(q*q+u*u)\n",
    "            aolp=0.5*np.arctan2(u, q)+np.pi/2\n",
    "    return iq,q,iu,u,i,q_phi,u_phi,pi,aolp,R,phi\n",
    "\n",
    "\n",
    "\n",
    "def load_and_make_polar_umon(dirdat,cycle,camera):\n",
    "    #q\n",
    "    dir = dirdat+'q_corr/'\n",
    "    qfile = '*_'+cycle+'_'+camera+'.fits'\n",
    "    files = os.listdir(dir)\n",
    "    for file in files:\n",
    "        if fnmatch.fnmatch(file, qfile):\n",
    "            hdulq = fits.open(dir + file)\n",
    "            q = hdulq[0].data\n",
    "            n=q.shape[0]\n",
    "    #u\n",
    "    dir = dirdat+'u_corr/'\n",
    "    qfile = '*_'+cycle+'_'+camera+'.fits'\n",
    "    files = os.listdir(dir)\n",
    "    for file in files:\n",
    "        if fnmatch.fnmatch(file, qfile):\n",
    "            hdulq = fits.open(dir + file)\n",
    "            u = hdulq[0].data\n",
    "    #qphi\n",
    "    dir = dirdat+'qphi_corr/'\n",
    "    qfile = '*_'+cycle+'_'+camera+'.fits'\n",
    "    files = os.listdir(dir)\n",
    "    for file in files:\n",
    "        if fnmatch.fnmatch(file, qfile):\n",
    "            hdulq = fits.open(dir + file)\n",
    "            qphi = hdulq[0].data\n",
    "            \n",
    "    #uphi\n",
    "    dir = dirdat+'uphi_corr/'\n",
    "    qfile = '*_'+cycle+'_'+camera+'.fits'\n",
    "    files = os.listdir(dir)\n",
    "    for file in files:\n",
    "        if fnmatch.fnmatch(file, qfile):\n",
    "            hdulq = fits.open(dir + file)\n",
    "            uphi = hdulq[0].data\n",
    "            \n",
    "            \n",
    "            \n",
    "    #iq,iu\n",
    "    dir = dirdat+'sci/'\n",
    "    qfile = '*_'+cycle+'_'+camera+'.fits'\n",
    "    files = os.listdir(dir)\n",
    "    for file in files:\n",
    "        if fnmatch.fnmatch(file, qfile):\n",
    "            hdulq = fits.open(dir + file)\n",
    "            iq = hdulq[0].data[0]\n",
    "            iu = hdulq[0].data[2]\n",
    "            \n",
    "            \n",
    "            \n",
    "             #Creating grid         \n",
    "            xr = np.linspace(-n/2, n/2, num=n)\n",
    "            yr = np.linspace(-n/2, n/2, num=n)\n",
    "            x0 = 0.5\n",
    "            y0 = 0.5\n",
    "            xr = xr-x0\n",
    "            yr = yr-y0\n",
    "            Xr, Yr = np.meshgrid(xr, yr)\n",
    "            R = np.sqrt(Xr**2 + Yr**2)\n",
    "            phi = np.arctan(Yr/Xr)\n",
    "            \n",
    "            i=(iq+iu)/2\n",
    "            \n",
    "            qphi = (qphi > 0)*qphi +  (qphi <=0 )*1e-10\n",
    "            pi=np.sqrt(q*q+u*u)\n",
    "            aolp=0.5*np.arctan2(u, q)+np.pi/2\n",
    "            \n",
    "    return iq,q,iu,u,i,qphi,uphi,pi,aolp,R,phi\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Loadimage(dirdat,filename):\n",
    "    dir =dirdat\n",
    "    psfile =  filename\n",
    "    files = os.listdir(dir)\n",
    "    for file in files:\n",
    "        if fnmatch.fnmatch(file, psfile):\n",
    "            hdulPSF = fits.open(dir + file)\n",
    "            fit = hdulPSF[0].data\n",
    "\n",
    "            \n",
    "    return fit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53bc44d6-ebcc-4518-844e-4d99c394dce1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_tel_corr(dirdat,camera,process):\n",
    "    dir = dirdat\n",
    "    files = os.listdir(dir)\n",
    "    qfile = 'qcorr_'+str(process)+'_'+str(camera)+'.fits'\n",
    "    ufile = 'ucorr_'+str(process)+'_'+str(camera)+'.fits'\n",
    "    qphifile = 'qphi_'+str(process)+'_'+str(camera)+'.fits'\n",
    "    uphifile = 'uphi_'+str(process)+'_'+str(camera)+'.fits'\n",
    "    \n",
    "    for file in files:\n",
    "        if fnmatch.fnmatch(file, qfile):\n",
    "            hdulq = fits.open(dir + file)\n",
    "            q = hdulq[0].data\n",
    "        if fnmatch.fnmatch(file, ufile):\n",
    "            hdulq = fits.open(dir + file)\n",
    "            u = hdulq[0].data\n",
    "        #if fnmatch.fnmatch(file, qphifile):\n",
    "        #    hdulq = fits.open(dir + file)\n",
    "        #    q_phi = hdulq[0].data\n",
    "        #if fnmatch.fnmatch(file, uphifile):\n",
    "        #    hdulq = fits.open(dir + file)\n",
    "        #    u_phi = hdulq[0].data    \n",
    "            \n",
    "            \n",
    "    n=q.shape[0]\n",
    "     #Creating grid         \n",
    "    xr = np.linspace(-n/2, n/2, num=n)\n",
    "    yr = np.linspace(-n/2, n/2, num=n)\n",
    "    x0 = 0.5\n",
    "    y0 = 0.5\n",
    "    xr = xr-x0\n",
    "    yr = yr-y0\n",
    "    Xr, Yr = np.meshgrid(xr, yr)\n",
    "    R = np.sqrt(Xr**2 + Yr**2)\n",
    "    phi = np.arctan(Yr/Xr)\n",
    "    q_phi=q*np.cos(2*phi)+u*np.sin(2*phi)\n",
    "    q_phi = (q_phi > 0)*q_phi +  (q_phi <=0 )*1e-10\n",
    "    u_phi=q*np.sin(2*phi)+u*np.cos(2*phi)    \n",
    "    \n",
    "    return q,u,q_phi,u_phi\n",
    "\n",
    "\n",
    "def createfolder(dirName):\n",
    "    try:\n",
    "    # Create target Directory\n",
    "       os.mkdir(dirName)\n",
    "    except FileExistsError:\n",
    "        print()#(\"Directory \" , dirName ,  \" already exists\")   \n",
    "        \n",
    "        \n",
    "def maskcrit(aolp,R):\n",
    "    phi = (aolp-90)  \n",
    "    n=aolp.shape[0]\n",
    "    critarray=np.zeros_like(phi)\n",
    "    for ix in range (0,n):\n",
    "        for iy in range(0,n):\n",
    "            if phi[ix,iy]>180:\n",
    "                phi[ix,iy]=phi[ix,iy]-180\n",
    "            \n",
    "    for ix in range (2,n-2):\n",
    "        for iy in range(2,n-2):\n",
    "            if R[ix,iy]>=1:            \n",
    "                datapix=[]\n",
    "                for (iix,iiy) in [(ix,iy),(ix-1,iy),(ix+1,iy),(ix,iy-1),(ix,iy+1)]: \n",
    "                    if R[iix,iiy]>=1:\n",
    "                        datapix.append(abs(phi[iix,iiy]))\n",
    "                            \n",
    "                \n",
    "                crit=np.std(datapix)               \n",
    "                critarray[ix,iy]=crit\n",
    "                \n",
    "    for ix in range (0,n-1):\n",
    "        for iy in range(0,n-1):\n",
    "            if critarray[ix,iy]==0:\n",
    "                critarray[ix,iy]=np.max(critarray)\n",
    "    medianstd=np.nanmedian(critarray)\n",
    "    \n",
    "    mask=(critarray<=medianstd)#*R([ix,iy]>=1)\n",
    "    return mask\n",
    "        \n",
    "def plot_AoLP(ps,R,Q,U,I,Q_PHI,PI,AOLP,title,save):\n",
    "    # First, we plot the background image\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    i_plot = fig.add_subplot(111)\n",
    "    n = I.shape[0]\n",
    "    d = n * ps / 2\n",
    "\n",
    "    im1=i_plot.imshow(np.arcsinh(Q_PHI), origin='lower',extent=(-d, d, d, -d))\n",
    "\n",
    "    fig.colorbar(im1, orientation='vertical')\n",
    "\n",
    "    plt.xlabel('mas')\n",
    "    plt.ylabel(\"mas\")\n",
    "    plt.tight_layout(pad=0.1)     \n",
    "\n",
    "    # ranges of the axis\n",
    "    xx0, xx1 = i_plot.get_xlim()\n",
    "    yy0, yy1 = i_plot.get_ylim()\n",
    "\n",
    "    # binning factor\n",
    "    factor = [4, 4]\n",
    "\n",
    "    # re-binned number of points in each axis\n",
    "    nx_new = PI.shape[1] // factor[0]\n",
    "    ny_new = PI.shape[0] // factor[1]\n",
    "\n",
    "    # These are the positions of the quivers\n",
    "    X,Y = np.meshgrid(np.linspace(xx0,xx1,nx_new,endpoint=True),\n",
    "                      np.linspace(yy0,yy1,ny_new,endpoint=True))\n",
    "    # bin the data\n",
    "    I_bin = I.reshape(nx_new, factor[0], ny_new, factor[1]).sum(3).sum(1)\n",
    "    Q_bin = Q.reshape(nx_new, factor[0], ny_new, factor[1]).sum(3).sum(1)\n",
    "    U_bin = U.reshape(nx_new, factor[0], ny_new, factor[1]).sum(3).sum(1)\n",
    "    Q_phi_bin = Q_PHI.reshape(nx_new, factor[0], ny_new, factor[1]).sum(3).sum(1)\n",
    "    PI_bin=PI.reshape(nx_new, factor[0], ny_new, factor[1]).sum(3).sum(1)\n",
    "    R_bin=R.reshape(nx_new, factor[0], ny_new, factor[1]).sum(3).sum(1)\n",
    "    aolp_bin=AOLP.reshape(nx_new, factor[0], ny_new, factor[1]).sum(3).sum(1)\n",
    "\n",
    "    # polarization angle\n",
    "    psi=0.5*np.arctan2(U_bin, Q_bin)\n",
    "\n",
    "    #psi=aolp_bin\n",
    "    #i_plot.imshow(psi, origin='lower',extent=(-d, d, d, -d))\n",
    "\n",
    "    # polarization fraction\n",
    "    frac =Q_phi_bin/I_bin\n",
    "    #frac=dolp_v[adc:bdc,adc:bdc]\n",
    "    # mask to show only alighned\n",
    "\n",
    "    mask1=maskcrit(psi,R_bin)\n",
    "    mask2=Q_phi_bin>=10\n",
    "    mask=mask2#*mask1\n",
    "    #print('max DoLP in region %.3f percent'%(np.max(frac[mask])*100))\n",
    "\n",
    "    #+pi/2 because quiver function start counting from the horizontal axis counterclockwise \n",
    "    #and the AoLP have to start from North to East (which is also counterclockvise)\n",
    "    pixX = frac*np.cos(psi+np.pi/2) # X-vector \n",
    "    pixY = frac*np.sin(psi+np.pi/2) # Y-vector\n",
    "\n",
    "    # keyword arguments for quiverplots\n",
    "    quiveropts = dict(headlength=0, headwidth=1, pivot='middle', color='w')\n",
    "    i_plot.quiver(X[mask], Y[mask], pixX[mask], pixY[mask],scale=2, **quiveropts)\n",
    "    plt.title(title)\n",
    "    plt.savefig(save,bbox_inches='tight', pad_inches=0.1)\n",
    "    #plt.show()#(dirName+\"aolp.jpeg\",bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.close()\n",
    "    \n",
    "def gaus(x,a,x0,sigma):\n",
    "            return a*np.exp(-(x-x0)**2/(2*sigma**2))\n",
    "\n",
    "    \n",
    "def find_FWHM (PSF,n,ps,figfolder,title):             #resolution\n",
    "    middle=int(n/2)\n",
    "\n",
    "    y1=PSF[middle,middle-60:middle+60]\n",
    "    y2=PSF[middle-60:middle+60,middle]\n",
    "\n",
    "    xdata = np.linspace(middle-60,middle+60, num=len(y1))\n",
    "\n",
    "\n",
    "    n_gauss = len(xdata) #the number of data\n",
    "    amp=np.max(y1)\n",
    "    mean = np.sum(xdata * y1) / sum(y1)\n",
    "    sigma = np.sqrt(sum(y1 * (xdata - mean)**2) / sum(y1))\n",
    "\n",
    "    popt1,pcov1 = curve_fit(gaus,xdata,y1,p0=[amp,mean,sigma])\n",
    "    popt2,pcov2 = curve_fit(gaus,xdata,y2,p0=[amp,mean,sigma])\n",
    "\n",
    "\n",
    "    plt.plot(xdata, y1, 'o', label='vertical')\n",
    "    plt.plot(xdata, gaus(xdata,*popt1), '-', label='fit1')\n",
    "    plt.plot(xdata, y2, 'o', label='horizotal')\n",
    "    plt.plot(xdata, gaus(xdata,*popt2), '-', label='fit2')\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.savefig(figfolder+title+'.jpeg',bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.close()\n",
    "\n",
    "    fwhm1=2*np.sqrt(2*math.log(2))*popt1[2]\n",
    "    fwhm2=2.355*popt2[2]\n",
    "\n",
    "\n",
    "    fwhm=(abs(fwhm1)+abs(fwhm2))/2\n",
    "\n",
    "    return fwhm\n",
    "\n",
    "def ap_fixed_in(rad,R,q,u,PSF):            \n",
    "    mask = (R <= rad)\n",
    "    q_sum = np.sum(q[mask])\n",
    "    u_sum = np.sum(u[mask])\n",
    "    psf_sum = np.sum(PSF[mask])\n",
    "    q_i_percent = q_sum / psf_sum * 100\n",
    "    u_i_percent = u_sum / psf_sum * 100\n",
    "    return psf_sum, q_sum, u_sum, q_i_percent, u_i_percent\n",
    "\n",
    "def ap(radin,radout,R,q,u,PSF):\n",
    "    mask = (R <= radout) * (R >= radin)\n",
    "    q_sum = np.sum(q[mask])\n",
    "    u_sum = np.sum(u[mask])\n",
    "    psf_sum = np.sum(PSF[mask])\n",
    "    q_i_percent = q_sum / psf_sum * 100\n",
    "    u_i_percent = u_sum / psf_sum * 100\n",
    "\n",
    "    return psf_sum, q_sum, u_sum, q_i_percent, u_i_percent\n",
    "\n",
    "def Loadimagespsf_AR(star):\n",
    "    dir = '/media/kateryna/Data_Lin/PhD/SPHERE_reduction_data/classic_reduction/'+star+'/'\n",
    " \n",
    "    psfile =  '*REDUCED_I.fits'\n",
    "    files = os.listdir(dir)\n",
    "    for file in files:\n",
    "        if fnmatch.fnmatch(file, psfile):\n",
    "            hdulPSF = fits.open(dir + file)\n",
    "            PSFv = hdulPSF[0].data[0]\n",
    "            PSFi = hdulPSF[0].data[1]\n",
    "\n",
    "            \n",
    "    return PSFv,PSFi\n",
    "\n",
    "\n",
    "def unres_correction(iq,iu,q,u):\n",
    "\n",
    "    n=q.shape[0]\n",
    "     #Creating grid         \n",
    "    xr = np.linspace(-n/2, n/2, num=n)\n",
    "    yr = np.linspace(-n/2, n/2, num=n)\n",
    "    x0 = 0.5\n",
    "    y0 = 0.5\n",
    "    xr = xr-x0\n",
    "    yr = yr-y0\n",
    "    Xr, Yr = np.meshgrid(xr, yr)\n",
    "    R = np.sqrt(Xr**2 + Yr**2)\n",
    "    phi = np.arctan(Yr/Xr)\n",
    "    i=(iq+iu)/2\n",
    "    mask=(R<=3)\n",
    "\n",
    "    q_over_i=np.divide(q,i,where=i!=0)   \n",
    "    cq=np.median(q_over_i[mask]) #for median normal as in IRDIS\n",
    "    u_over_i=np.divide(u,i,where=i!=0)    \n",
    "    cu=np.median(u_over_i[mask]) #for median normal as in IRDIS\n",
    "    q_corr=q-cq*iq\n",
    "    u_corr=u-cu*iu\n",
    "\n",
    "    q_phi=q_corr*np.cos(2*phi)+u_corr*np.sin(2*phi)\n",
    "    q_phi= (q_phi> 0)*q_phi +  (q_phi <=0 )*1e-10\n",
    "    u_phi=q_corr*np.sin(2*phi)+u_corr*np.cos(2*phi)\n",
    "    pi=np.sqrt(q_corr*q_corr+u_corr*u_corr)\n",
    "    aolp=0.5*np.arctan2(u, q)+np.pi/2\n",
    "\n",
    "    return iq,q_corr,iu,u_corr,i,q_phi,u_phi,pi,aolp,R,phi\n",
    "\n",
    "\n",
    "\n",
    "def load_I(dirdat,camera):\n",
    "    dir = dirdat\n",
    "    qfile = '*sci'+camera+'.fits'\n",
    "    files = os.listdir(dir)\n",
    "    for file in files:\n",
    "        if fnmatch.fnmatch(file, qfile):\n",
    "            hdulq = fits.open(dir + file)\n",
    "            iq = hdulq[0].data[0]\n",
    "            q = hdulq[0].data[1]\n",
    "            iu = hdulq[0].data[2]\n",
    "            u = hdulq[0].data[3]\n",
    "            n=q.shape[0]\n",
    "            i=(iq+iu)/2\n",
    "            \n",
    "    return iq,iu,i\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60b5e66-0589-41ae-a287-74468a11d884",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Downloding files and selecting top percent by peak I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "646810cf-52e4-4878-acfa-b9d0d9c8396e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000532\n",
      "0.000752\n",
      "{'AR_Pup_17c_00_12-13_not_norm': 481358, 'AR_Pup_16c_00_10-11_not_norm': 481357, 'AR_Pup_15c_00_08-09_not_norm': 481356, 'AR_Pup_14c_00_06-07_not_norm': 481355, 'AR_Pup_13c_00_04-05_not_norm': 481354, 'AR_Pup_12c_00_02-03_not_norm': 481353, 'AR_Pup_11c_00_00-02(1)_not_norm': 481352, 'AR_Pup_10c_23_58-00(1)_not_norm': 481351, 'AR_Pup_9c_23_56-58(1)_not_norm': 481350, 'AR_Pup_7c_23_53-54(1)_not_norm': 481348, 'AR_Pup_6c_23_51-52_not_norm': 481347, 'AR_Pup_5c_23_49-50_not_norm': 481346, 'AR_Pup_4c_23_47-48_not_norm': 481345, 'AR_Pup_3c_23_45-46_not_norm': 481344, 'AR_Pup_2c_23_43-44_not_norm': 481343}\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#stars=['HD83878','IRAS08544-4431_dc_notnorm','HD75885', 'AR_Pup_dc_notnorm','UMon','HR4049_20190108','HR4049_20190107','HD71253','HD94680','HD96314','HD98025','V709_Car','HR4226']\n",
    "stars=['HD75885', 'AR_Pup_dc_notnorm']\n",
    "star=stars[1]\n",
    "\n",
    "starnames = {'HD75885':'HD75885','AR_Pup':'AR_Pup','HR4049/2019-01-08':'HR4049-2019-01-08','HR4049/2019-01-07':'HR4049-2019-01-07','IRAS08544-4431':'IRAS08544-4431','UMon':'UMon','AR_Pup_flat4':'AR_Pup_flat4','V709_Car':'V709_Car','UMon_calibV390':'UMon_calibV390','HR4224':'HR4224','UMon_Katya':'UMon_Katya'}\n",
    "fittypes=['1', '2']\n",
    "\n",
    "band=['V','I']\n",
    "ps=3.6\n",
    "\n",
    "\n",
    "if star=='AR_Pup':\n",
    "    dirdat = '//media/kateryna/Data_Lin/PhD/SPHERE_reduction_data/individual_cycles/AR_Pup/Normalised/'  #For AR_Pup\n",
    "    input_filename =dirdat+'AR_Pup_indiv_process_list.csv'\n",
    "elif star=='AR_Pup_dc_notnorm':\n",
    "    dirdat = '//media/kateryna/Data_Lin/PhD/SPHERE_reduction_data/individual_cycles/AR_Pup/Not_normalised/'  #For AR_Pup\n",
    "    input_filename =dirdat+'AR_Pup_no_norm_indiv_process_list.csv'\n",
    "\n",
    "elif star=='IRAS08544-4431':\n",
    "    dirdat = '//media/kateryna/Data_Lin/PhD/SPHERE_reduction_data/individual_cycles/IRAS08544-4431/Normalised/'  #For IRAS08\n",
    "    input_filename =dirdat+'IRAS08process_list.csv'\n",
    "elif star=='IRAS08544-4431_dc_notnorm':\n",
    "    dirdat = '//media/kateryna/Data_Lin/PhD/SPHERE_reduction_data/individual_cycles/IRAS08544-4431/Not_normalised/'  #For IRAS08\n",
    "    input_filename =dirdat+'IRAS08_not_norm_indiv_process_list.csv'\n",
    "\n",
    "elif star=='UMon':\n",
    "    dirdat = '//media/kateryna/Data_Lin/PhD/SPHERE_reduction_data/paper3/UMon_data/HansMartin/'\n",
    "    input_filename =dirdat+'UMon_cycle_list.csv'\n",
    "\n",
    "else:\n",
    "    dirdat = '//media/kateryna/Data_Lin/PhD/SPHERE_reduction_data/individual_cycles/'+star+'/' \n",
    "    input_filename =dirdat+'process_list.csv'\n",
    "    \n",
    "table = pd.read_csv(input_filename)\n",
    "table['reference']= table['reference'].str.replace(' ', '_') #ix in case there are spaces in the name\n",
    "\n",
    "\n",
    "figfolder='//media/kateryna/Data_Lin/PhD/SPHERE_reduction_data/paper3/'+'Quality_indiv_cycles/'+ star+'/'\n",
    "\n",
    "\n",
    "output_filename = figfolder+star+'_V_Original_AP_per_cycle.txt'\n",
    "df_orig_v = pd.read_csv(output_filename, delim_whitespace=True)\n",
    "output_filename = figfolder+star+'_I_Original_AP_per_cycle.txt'\n",
    "df_orig_i = pd.read_csv(output_filename, delim_whitespace=True)\n",
    "\n",
    "#stars = ['HD75885','AR_Pup','HR4049/2019-01-08','HR4049/2019-01-07','IRAS08544-4431','UMon','V709_Car','UMon_calibV390','HR4224']\n",
    "\n",
    "\n",
    "processes=table['id']\n",
    "\n",
    "reference={process:ref for process,ref in zip(table['id'], table['reference'])}\n",
    "process_dict={ref:process for process,ref in zip(table['id'], table['reference'])}\n",
    "\n",
    "percentile_25 = np.percentile(df_orig_v['Peak_i(Strehl)'], 25)\n",
    "print(percentile_25)\n",
    "print(np.max(df_orig_v['Peak_i(Strehl)']))\n",
    "\n",
    "#filtering list of processes\n",
    "filtered_process_dict = {key: value for key, value in process_dict.items() if df_orig_v[df_orig_v['reference'] == key]['Peak_i(Strehl)'].values[0] >=percentile_25}\n",
    "\n",
    "print(filtered_process_dict)\n",
    "print(len(filtered_process_dict))\n",
    "\n",
    "#for key, value in process_dict.items():\n",
    " #   print(key, df_orig_v[df_orig_v['reference'] == key]['FWHM'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d5c45f3-4c92-41e1-8f69-6967c39539f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "V\n",
      "\n",
      "I\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import csv\n",
    "\n",
    "fitsfolder='//media/kateryna/Data_Lin/PhD/SPHERE_reduction_data/paper3/'+'filtered/'\n",
    "createfolder(fitsfolder)\n",
    "fitsfolder=fitsfolder+star+'/'\n",
    "createfolder(fitsfolder)\n",
    "fitsfolder=fitsfolder+'selected/'\n",
    "createfolder(fitsfolder)\n",
    "\n",
    "\n",
    "\n",
    "with open(fitsfolder+'filtered_process_list.csv', 'w', newline='') as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow(['reference', 'process'])\n",
    "    \n",
    "    for reference,process in filtered_process_dict.items():\n",
    "        csv_writer.writerow([reference,process])\n",
    "        \n",
    "        \n",
    "        \n",
    "for fittype in fittypes:\n",
    "    \n",
    "    fitsfolder0=fitsfolder+'cam'+fittype+'/'\n",
    "    createfolder(fitsfolder0)\n",
    "    print(band[int(fittype)-1])\n",
    "    for key in filtered_process_dict.keys():\n",
    "        process=filtered_process_dict[key]\n",
    "        if star!='UMon':\n",
    "            dirName=dirdat+'SPHERE_DC_DATA/'+str(process)+'/'\n",
    "            qfile = '*sci'+fittype+'.fits'\n",
    "            files = os.listdir(dirName)\n",
    "            for file in files:\n",
    "                if fnmatch.fnmatch(file, qfile):\n",
    "                    shutil.copyfile(dirName+file,fitsfolder0+str(process)+'_'+file)\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "        if star=='UMon':\n",
    "            for folder in ['q_corr','u_corr','qphi_corr','uphi_corr','sci']:\n",
    "                fitsfolder_sub=fitsfolder0+folder+'/'\n",
    "                createfolder(fitsfolder_sub)    \n",
    "                dirName=dirdat+folder+'/'\n",
    "                qfile = '*'+process+'_'+fittype+'.fits'\n",
    "\n",
    "                files = os.listdir(dirName)\n",
    "                for file in files:\n",
    "                    if fnmatch.fnmatch(file, qfile):\n",
    "                        shutil.copyfile(dirName+file,fitsfolder_sub+str(process)+'_'+file)\n",
    "                       \n",
    "                \n",
    "                \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ae4283-38fc-4825-9e11-5b00340e2501",
   "metadata": {},
   "source": [
    "## Mean combining I total and saving as fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ff6d49f-d186-41c5-8430-295f709e3da2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "reference                      Peak_I(Strehl)  \n",
      "\n",
      "V\n",
      "raw                            0.001      \n",
      "\n",
      "I\n",
      "raw                            0.001      \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Images of the mean_combined data\n",
    "figfolder='//media/kateryna/Data_Lin/PhD/SPHERE_reduction_data/paper3/'+'filtered/'\n",
    "createfolder(figfolder)\n",
    "figfolder=figfolder+star+'/'\n",
    "createfolder(figfolder)\n",
    "print(\"{:<30} {:<10}  \\n\".format('reference', 'Peak_I(Strehl)'))\n",
    "\n",
    "\n",
    "\n",
    "for fittype in fittypes:\n",
    "    print(band[int(fittype)-1])\n",
    "    iq_arr=[]\n",
    "    iu_arr=[]\n",
    "    q_arr=[]\n",
    "    u_arr=[]\n",
    "    i_arr=[]\n",
    "    q_phi_arr=[]\n",
    "    u_phi_arr=[]\n",
    "    pi_arr=[]\n",
    "    \n",
    "    for key in filtered_process_dict.keys():\n",
    "        process=filtered_process_dict[key]\n",
    "        if star=='UMon':\n",
    "            dirName=dirdat\n",
    "        else:\n",
    "            dirName=dirdat+'SPHERE_DC_DATA/'+str(process)+'/'\n",
    "        if star=='UMon':\n",
    "            iq,_,iu,_,i,_,_,_,_,_,_= load_and_make_polar_umon(dirName,process,fittype)\n",
    "        else:        \n",
    "            iq,iu,i= load_I(dirName,fittype)\n",
    "        iq_arr.append(iq)\n",
    "        iu_arr.append(iu)\n",
    "        i_arr.append(i)\n",
    "        \n",
    "    iq_arr=np.array(iq_arr)\n",
    "    iu_arr=np.array(iu_arr)\n",
    "    i_arr=np.array(i_arr)\n",
    "    \n",
    "    \n",
    "    iq_mean_comb=np.mean(iq_arr,axis=0)\n",
    "    iu_mean_comb=np.mean(iu_arr,axis=0)\n",
    "    i_mean_comb=np.mean(i_arr,axis=0)\n",
    "    \n",
    "        \n",
    "    n=iq_mean_comb.shape[0]\n",
    "    if star=='AR_Pup' or star=='AR_Pup_dc_notnorm':\n",
    "        lim=100       \n",
    "    else:\n",
    "        lim=50       \n",
    "            \n",
    "    xr = np.linspace(-n/2, n/2, num=n)\n",
    "    yr = np.linspace(-n/2, n/2, num=n)\n",
    "    x0 = 0.5\n",
    "    y0 = 0.5\n",
    "    xr = xr-x0\n",
    "    yr = yr-y0\n",
    "    Xr, Yr = np.meshgrid(xr, yr)\n",
    "    R = np.sqrt(Xr**2 + Yr**2)\n",
    "    \n",
    "    mask=(R<=1500/ps)\n",
    "    I_sum=np.sum(i_mean_comb[mask])\n",
    "    \n",
    "    fwhm=find_FWHM (i_mean_comb,n,ps,figfolder,band[int(fittype)-1]+'_gauss_mean_combined')\n",
    "    \n",
    "    \n",
    "    mask=(R<=1500/ps)\n",
    "    #calculating what is the ratio of peak brightness to the total. For I it refers to the observational conditions and is a proxy of strehl\n",
    "    normalisation=np.sum(i_mean_comb[mask])\n",
    "    peak_i=np.max(i_mean_comb*(R<200))/normalisation\n",
    "    \n",
    "    line = \"{:<30} {:<10.3f} \\n\".format('raw',peak_i)\n",
    "    print(line)\n",
    "        \n",
    "    \n",
    "    \n",
    "    filename={0:'I'}\n",
    "\n",
    "    for fileindex,image1 in enumerate([i_mean_comb]):\n",
    "        out_fits = fits.HDUList(fits.PrimaryHDU(image1))                  # create output fits structure\n",
    "        out_fits.writeto(figfolder+star+'_'+band[int(fittype)-1]+'_'+filename[fileindex]+'_meancombined.fits', overwrite = True)                       # write output\n",
    "\n",
    "        image_an = image1*(R<250)\n",
    "        image=np.arcsinh(image_an)\n",
    "        fig, ax = plt.subplots()\n",
    "        f.plottingroutinemas(image,lim,ps,n,star,ax)        \n",
    "        f.scale_mas(star,ax)  \n",
    "\n",
    "        plt.title(star+', '+filename[fileindex]+', '+band[int(fittype)-1]+', mean combined') \n",
    "        plt.savefig(figfolder+star+'_'+band[int(fittype)-1]+'_'+filename[fileindex]+'_'+'_meancombined.jpeg',bbox_inches='tight', pad_inches=0.1)\n",
    "        #plt.show()\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b10e41-69a7-4117-b174-18f9d2089ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
